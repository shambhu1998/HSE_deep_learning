{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2185ab0278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 55\n"
     ]
    }
   ],
   "source": [
    "tokens = list(set(''.join(names)))### YOUR CODE HERE: all unique characters go here, padding included!\n",
    "\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {token: i for i,token in enumerate(tokens)}### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[17 24 33 11 16 11  0 52  0]\n",
      " [17 53 52 25  1 27  0  0  0]\n",
      " [17 34  1 35 15 15 35  0  0]\n",
      " [17 53 35 25 49 11 32 32  0]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation=\"relu\")### YOUR CODE HERE\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation=\"softmax\")### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = tf.concat([x_t_emb, h_t], 1)### YOUR CODE HERE\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "from keras.objectives import categorical_crossentropy\n",
    "\n",
    "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix)) ### YOUR CODE HERE\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VNX5+PHPMzNZIAlbCGEJGDbZBSQgCCKCCIKVqlhr\nWxdcaNVW+7W1X1yKtWqx7l+/bvXrhtZS/ClVCioKgoBaZN9BkDUQSAiQDbKf3x9zZzIzmSSTZMKQ\nm+f9euXFzJ07M2cy4bnnPuc554oxBqWUUvbiiHQDlFJKhZ8Gd6WUsiEN7kopZUMa3JVSyoY0uCul\nlA1pcFdKKRvS4K6UUjakwV0ppWxIg7tSStmQK1Jv3LZtW5Oamhqpt1dKqUZp7dq1x4wxSTXtF7Hg\nnpqaypo1ayL19kop1SiJyP5Q9tO0jFJK2ZAGd6WUsiEN7kopZUMRy7krpVQ4lJSUkJ6eTmFhYaSb\nElaxsbGkpKQQFRVVp+drcFdKNWrp6ekkJCSQmpqKiES6OWFhjCE7O5v09HS6du1ap9cIOS0jIk4R\nWS8iC4I8FiMic0Vkt4isEpHUOrVGKaVqqbCwkMTERNsEdgARITExsV5nI7XJud8DbK/isVuBE8aY\nHsBzwF/r3CKllKolOwV2j/p+ppCCu4ikAJOB16vYZQow27r9ATBOGui3nX7iFI/8eyslZeUN8fJK\nKWULofbcnwf+AFQVUTsBBwGMMaVADpBY79YFse1wLm99vY+3v97XEC+vlFK1Fh8fH+kmVFJjcBeR\nK4BMY8za+r6ZiEwXkTUisiYrK6tOrzG+bzJje7fj+cXfcyy/qL5NUkopWwql5z4SuFJE9gH/BMaK\nyN8D9jkEdAYQERfQEsgOfCFjzGvGmDRjTFpSUo1LIwQlIjw4uQ+nS8p4bfmeOr2GUko1BGMM9913\nH/3792fAgAHMnTsXgIyMDEaPHs2gQYPo378/K1asoKysjJtvvtm773PPPRfWttRYCmmMuR+4H0BE\nxgC/N8b8ImC3+cBNwLfAVOBLY4wJa0t9dE+KZ8qgTrz77X7uGdeTuBit6FRKwSP/3sq2w7lhfc2+\nHVvw8I/6hbTvvHnz2LBhAxs3buTYsWMMHTqU0aNH849//IMJEybw4IMPUlZWxqlTp9iwYQOHDh1i\ny5YtAJw8eTKs7a7zDFUR+bOIXGndfQNIFJHdwL3AjHA0rjrXDe3M6ZIylu2sW3pHKaXCbeXKlVx/\n/fU4nU6Sk5O5+OKLWb16NUOHDuWtt97iT3/6E5s3byYhIYFu3bqxZ88efvOb3/DZZ5/RokWLsLal\nVl1eY8wyYJl1e6bP9kLg2nA2rCZDU9uQGBfNp1symHxehzP51kqps1SoPewzbfTo0SxfvpyFCxdy\n8803c++993LjjTeyceNGFi1axKuvvsr777/Pm2++Gbb3bLRryzgdwmX9klm6I5PCkrJIN0cppbjo\noouYO3cuZWVlZGVlsXz5coYNG8b+/ftJTk7m9ttv57bbbmPdunUcO3aM8vJyrrnmGh577DHWrVsX\n1rY06mT1+L7JzPnuIOsPnGRE9wapvFRKqZBdddVVfPvttwwcOBAR4cknn6R9+/bMnj2bp556iqio\nKOLj43nnnXc4dOgQ06ZNo7zcXWE+a9assLZFGnDcs1ppaWmmvhfrOJJTyPBZS3h0Sj9uGJEanoYp\npRqV7du306dPn0g3o0EE+2wistYYk1bTcxttWgYguUUMCTEuvj+aH+mmKKXUWaVRB3cRoWdyPLsy\n8yLdFKWUOqs06uAO0LNdAru0565Ukxap9HJDqu9navzBPTme7IJisnUpAqWapNjYWLKzs20V4D3r\nucfGxtb5NRp1tQxASuvmAGTkFJIYHxPh1iilzrSUlBTS09Op63pVZyvPlZjqqtEH93Yt3AE9K097\n7ko1RVFRUXW+WpGdNfq0TFK8BnellArU+IN7ghXcNeeulFJejT64x0Y5aRHrIjPXXlc+V0qp+mj0\nwR3cvXftuSulVAVbBPd2CbFk5mpwV0opD1sEd+25K6WUP/sEd62WUUopL1sE97bxMZwqLuNUcWmk\nm6KUUmcFWwT3hFj3XKz8Qg3uSikFNgnu8dYFsvOLNLgrpRRocFdKKVuyRXCP0+CulFJ+bBHcNeeu\nlFL+bBHcPT33Aq2WUUopIITgLiKxIvKdiGwUka0i8kiQfW4WkSwR2WD93NYwzQ0uLsYJaM9dKaU8\nQlnPvQgYa4zJF5EoYKWIfGqM+U/AfnONMb8OfxNrlhATBUB+UVkk3l4ppc46NQZ34752lecipVHW\nz1l1PavYKAcOgfyikkg3RSmlzgoh5dxFxCkiG4BM4AtjzKogu10jIptE5AMR6RzWVtbcPuJjXBRo\nz10ppYAQg7sxpswYMwhIAYaJSP+AXf4NpBpjzgO+AGYHex0RmS4ia0RkTbivdxgf49JSSKWUstSq\nWsYYcxJYCkwM2J5tjPGs3PU6MKSK579mjEkzxqQlJSXVpb1Vahbt1LVllFLKEkq1TJKItLJuNwPG\nAzsC9ungc/dKYHs4GxmKGJeT4tLyM/22Sil1VgqlWqYDMFtEnLgPBu8bYxaIyJ+BNcaY+cDdInIl\nUAocB25uqAZXJSbKQZEGd6WUAkKrltkEDA6yfabP7fuB+8PbtNqJcWlwV0opD1vMUAWIdjk1uCul\nlMU2wT3G5aCoREshlVIKbBbcdUBVKaXcbBTcNS2jlFIetgnu0TqgqpRSXrYJ7u5qGc25K6UU2Cm4\nR2nOXSmlPOwT3K2cu3sRS6WUatpsFNzdH6W4THvvSillu+Cug6pKKWXD4K55d6WUslVwd19HVXvu\nSillo+Ae7UnL6BIESilln+CuOXellKpgn+AepTl3pZTysE1wj3Zqzl0ppTzsE9y1WkYppbxsE9xd\nTgGgtFyDu1JK2Se4O6zgXqbLDyillI2Cu/ujlJZrcFdKKfsEd03LKKWUl32Cu5WWKdOeu1JK2Sm4\nuz9KiebclVKq5uAuIrEi8p2IbBSRrSLySJB9YkRkrojsFpFVIpLaEI2tjictU6ZpGaWUCqnnXgSM\nNcYMBAYBE0VkeMA+twInjDE9gOeAv4a3mTXzpGW0566UUiEEd+OWb92Nsn4CI+gUYLZ1+wNgnIhI\n2FoZApfT/VE0566UUiHm3EXEKSIbgEzgC2PMqoBdOgEHAYwxpUAOkBjOhtbE6e25a1pGKaVCCu7G\nmDJjzCAgBRgmIv3r8mYiMl1E1ojImqysrLq8RJWivKWQ2nNXSqlaVcsYY04CS4GJAQ8dAjoDiIgL\naAlkB3n+a8aYNGNMWlJSUt1aXAWnlkIqpZRXKNUySSLSyrrdDBgP7AjYbT5wk3V7KvClMeaMRtko\nbymkpmWUUsoVwj4dgNki4sR9MHjfGLNARP4MrDHGzAfeAN4Vkd3AceCnDdbiKjgcgoj23JVSCkII\n7saYTcDgINtn+twuBK4Nb9NqL8rh0FJIpZTCRjNUwZ1310lMSills+Ducor23JVSCrsFd4dozl0p\npbBbcHc6dMlfpZTCbsHdIXolJqWUwm7B3Sk6Q1UppbBbcHc4NLgrpRS2C+5Cqc5QVUopewV3p0PT\nMkopBTYL7lFOh/bclVIKmwV37bkrpZSbrYJ7lFNLIZVSCmwW3J06Q1UppQCbBfcop4MSnaGqlFL2\nCu7ac1dKKTdbBXeXrueulFKA7YK7rueulFJgt+Cu1TJKKQXYLbhrnbtSSgF2C+46Q1UppQC7BXft\nuSulFGC34K7ruSulFGC34O7QtIxSSkEIwV1EOovIUhHZJiJbReSeIPuMEZEcEdlg/cxsmOZWT9My\nSinl5gphn1Lgd8aYdSKSAKwVkS+MMdsC9lthjLki/E0MnVPTMkopBYTQczfGZBhj1lm384DtQKeG\nblhdRGlaRimlgFrm3EUkFRgMrAry8AgR2Sgin4pIvzC0rdacDqHcQLn23pVSTVwoaRkARCQe+BD4\nrTEmN+DhdcA5xph8EZkEfAT0DPIa04HpAF26dKlzo6sS5RQASssN0Q4J++srpVRjEVLPXUSicAf2\n94wx8wIfN8bkGmPyrdufAFEi0jbIfq8ZY9KMMWlJSUn1bHplTof74+jKkEqppi6UahkB3gC2G2Oe\nrWKf9tZ+iMgw63Wzw9nQUHh67rqmu1KqqQslLTMSuAHYLCIbrG0PAF0AjDGvAlOBO0SkFDgN/NQY\nc8a7z04rFVOmi4cppZq4GoO7MWYlUG0C2xjzIvBiuBpVVy6n+0REe+5KqabOZjNUrZ675tyVUk2c\nLYO7rumulGrq7BXcfUohlVKqKbNXcLdKIXWWqlKqqbNZcNeeu1JKgd2Cu9PTc9fgrpRq2uwV3L09\nd03LKKWaNnsFdx1QVUopwGbB3amlkEopBdgsuEd5cu6allFKNXG2Cu5OrZZRSinAZsE9yqHVMkop\nBTYL7t5VITUto5Rq4mwV3L3ruWvPXSnVxNkquDt1VUillAJsFtw91TIluraMUqqJs1Vw1567Ukq5\n2Sq4u7zXUNXgrpRq2uwV3K1SyDJNyyilmjh7BXddW0YppQC7BXedoaqUUoDtgrteiUkppcBmwV0n\nMSmllJutgruI4HSIrgqplGryagzuItJZRJaKyDYR2Soi9wTZR0TkBRHZLSKbROT8hmluzVwO0YXD\nlFJNniuEfUqB3xlj1olIArBWRL4wxmzz2edyoKf1cwHwivXvGRfldGhaRinV5NXYczfGZBhj1lm3\n84DtQKeA3aYA7xi3/wCtRKRD2FsbApdT0zJKKVWrnLuIpAKDgVUBD3UCDvrcT6fyAQARmS4ia0Rk\nTVZWVu1aGiJ3z12Du1KqaQs5uItIPPAh8FtjTG5d3swY85oxJs0Yk5aUlFSXl6hRlEM0LaOUavJC\nCu4iEoU7sL9njJkXZJdDQGef+ynWtjPO5XRonbtSqskLpVpGgDeA7caYZ6vYbT5wo1U1MxzIMcZk\nhLGdIXM5RRcOU0o1eaFUy4wEbgA2i8gGa9sDQBcAY8yrwCfAJGA3cAqYFv6mhibKoT13pZSqMbgb\nY1YCUsM+BrgrXI2qD5dT69yVUspWM1TBnXMvtnruGw6eZOmOzAi3SCmlzrxQ0jKNSrRPz/3HL30N\nwL4nJkeySUopdcbZr+fucOgkJqVUk2e/4O4UijXnrpRq4mwX3JtHOzldXBrpZiilVETZLrjHx0RR\nUFQW6WYopVRE2TC4O8krLIl0M5RSKqLsF9xjXRQUl+EuvVdKqabJdsE9LsZFWbmhqFQrZpRSTZft\ngnt8jLt0P6/Qf1B12+Fc7c0rpZoM2wb3rLwi77bPthxh0gsr+PemiKxlppRSZ5ztgnucFdx/9fe1\n3m0b008CcCC7ICJtUkqpM812wT3BCu4Hjp/ybisocqdoPIFfKaXsznbBPVgAz9fgrpRqYppEcPcM\nrsa4bPdxlVIqKNtFu4TYysE997R7UlNBURmni8/c7NVyvSKUUipCbBfcg/XcV+09DsAD/9pMn5mf\nnZF2LNuZSbcHPmHLoZwz8n5KKeXLdsG9eZQTqfa6UWfGku3ui4SsO3Aiwi1RSjVFtgvuDodQm7lK\nuzPzeX/1wYZrkFJKRUCTLx+Z/MIKikrL+cnQzg3y+jopVikVCbbrudeWZw2a0rLwrkVzNqSGlFJN\nV5MM7mVBqlgaaqExXc9GKRUJtgzuj07pV+3jOacrr/fuG9xzC0vIzCusVxtq03Ef+/QyXlq6u17v\np5RSvmoM7iLypohkisiWKh4fIyI5IrLB+pkZ/mbWznkprap9/PxHv2DR1iO8t2q/d1tRaUX9+7hn\nvmLY40vq1Yba9Nf3HCvgqUU76/V+SinlK5QB1beBF4F3qtlnhTHmirC0KAwGdm7Fuj+O5/xHv6hy\nn1++u9bvflFJRc/dd0VJpZRqjGoM7saY5SKS2vBNCa82cdF0adPcbwGx6hw8cYoFmw6zMT08k450\nPFUpFUnhyrmPEJGNIvKpiFSf8D6Dlv/hElo2iwpp3xve+I6nP/+eL7Yd9W4rLAnfUgW3zV5N6oyF\nYXs9pZSqTjiC+zrgHGPMQOB/gY+q2lFEpovIGhFZk5WVFYa3rpnL4e5DXzmwY62fmxuGC217cu+L\nrRmrgXT9GaVUQ6h3cDfG5Bpj8q3bnwBRItK2in1fM8akGWPSkpKS6vvWIZl9yzCuH9aFZlHOWj/3\n4/WHAXcA3nesgPUHTnAgO7Q0j4RY6F6mpZJKqQZQ7+AuIu3FimQiMsx6zez6vm649O/UkllXD+DK\nQbXvuT/+yXYAZn26nTFPL+Oql79h9FNLK+13LL+IRVuP+G1bvN2d3qkpdgeruVdKqfoKpRRyDvAt\n0EtE0kXkVhH5lYj8ytplKrBFRDYCLwA/NWfhzJ2RPdqy9qFLAfdg6+s3poX83PdWHai0bf7Gw5wq\ndq8Tf9vsNfzy3bXk+aRx0k+cDum1SzW4K6UaQCjVMtfX8PiLuEslz3qJ8THsevxyXA5h7f7QVmt8\nY+VeTgWsAb87M5+756xn0oD2vPzzIey3rs06d/VBbruoW7Wvl51fRGJ8jPd+WZkGd6VU+Nlyhmp1\nopwORIT4IBf1ALjivA5+9x9dsK3SPl/vPgbAJ5uPkH7iFA4rv/7YQncaJzDVknOqokc/5LHFfo+V\nljfMsgeRZowhdcZC/vrZjkg3RakmqckFdw/fAdYxvSoGdz3VNdV5eP5W7+2ZH28lu6DYe7+wpIzT\nPiWUBpj+7poqXyvwQHDv3A38/T/7q9i7/gpLyvjT/K1Bl2AIpxLrjORvX/3QoO+jlAquyQb3Vs2j\nAbhh+Dm8PW2Yd/saK11z9fmdQnqdL3f4lzi+9fU++j+8yHvfGMPmaq7GFFgtM2/9IR76KOhKD15F\npWXc88/13nRQbXy0/hBvf7OPZz5v2OUOPGckoVYNKaXCq8kG95bNovj2/rHM/FFfv+2PTunP1CEp\nPHH1ed5tbeKiQ37dwDREWbmhdfPKzy8tK2fLoRxKfXLun23JqLRfzukSnlq0g2Kfhc1W7TnOxxsO\n13gQCMZzMCkJcYnjV7/6gdtmr671++hAsVKR1aQv1tGhZbNK2y7p3Y5Lerfz23bD8HP4nyW76vQe\nsz6tnHPeciiHhZszeGXZD7RqXjGD9ld/X+e9Peappfz20nPZejiH/1uxl3PaxHkvKFJuBei69Io9\n4wOh1jM9EaT9oSjVgWKlIqrJ9twD/eWqAcy4vLfftvsm9AJCX5P9sr7JIe135YsrWbPPfdHuk6eC\n5773ZZ/it3M3eIPxHz7cRHa+e0EzT3A3xtR6hqvncFDewNWqnoufaFJGqcjQ4G752QVd+NXF3f22\n3TqqK7eM7Mpto6svb/R4LcTa+XIDq/eFVor5t+V7vLc9lTYbDrpz+Ct2HaPbA59w53truXDWEg6f\nrLm23nOwCEfWZE9Wvl8lkC9PWqYpp9yz84tInbFQr9GrIkKDezVio5zM/FFfWsT6Lz4WWFHjdAi/\nv+zcal8rISY8GbCc0yW8EJAi+mTzEQ7nFAYt2wzkCbbBOu67M/M4aK2i+dmWDF5fUXFgCZajH/vM\nV0x5aWXQ9wklLZOVV8Snm/3HGdbuP8GhEA5SjcE+a8B7zurKk+CUamhNOudeV62aR3Msv4gbR5zD\n1sO5fHjHhT6PRQVNtSz6r9Fc+MSX9X7vompWqtxw8CRHcgpZujOTC7q2oVtSvPexu+es51RxKRP7\nu+v4g6WaLn12OQD7npjsl/8HdwlllLNyX2BfwFo7nitKTezfvsbP8ovXV7HzaB7b/zyRZtHu0tRr\nXvmGaJeD7x+7vMbnn+08Z0eOpnz6oiJGe+518NiP+9M2PoYHJvXxC+xQdd69hbX0cP9OLWr9fskt\nKma0Tg+4yIivjJxChs9awv3zNjP2ma9Ys+84S3e6SzXnbzzM4u2ZbDjoTgflnC7hn98d8AZ532Af\nLPAPfXwx9/xzvXcZ5KrGIZ5atJOnFu309tylmqz7D1n5ADy/5Hu/7cUNdD1bD2MMo59cyrx16Q38\nPu5/NbSrSNDgHqInp57HA5N6M+f24Uzs3541D11KbJCVJh/78QA+vGME/7l/HF/dNwZwT5iKj3Hx\n0s/O582bhtb6vT//7cVMHuDucW84eDLk50199VumvbXaLxD//T/uFMGSHZnMmLeZldZs2+M+E7F+\nyKpcP19YUs7HGw7z/GJ3SqikhrRLKDNvPXn5v33lTv80dFD3KCwp58DxU9z7/ka/9YDCzfN7r2/P\n/Y2Ve0k/EdpqpLWx9XBOyCWxZ5OSsnLvgL2qmgb3EP0krTPTR3dnRPfEaveLdjkYck4b2reM5ZzE\nOLY+MoG1f3QvWDb5vA60axFb6/dOiHWx5XDdrxC1aOvRKh+74Y3vAHj2i4re87pq1t05YR0EfK85\n6xnI3ZReceBZd8C6HWJcO15QzLtVzMwtLzccy6/60oe7M/P4P5+B56os3ZHJku1HvQu+Aew7VnXQ\nLCgq9fucoTDGeJ/jHbS2fgeldQhKx/KLeHTBNm5687taPa8m+44VMPmFlXUudQX4fOsRUmcs5Ghu\n/S4mX1u9//gZ459bfkbfszHS4N7A4mJcNI/2H9pYfO/FIT+/X8cWOBxCST16tb/6e9WpHIC8whK/\nlS//e96mKvedu+Yg3x/No9DnmrOe17/yxa+92/5YywlWd89Z7zcgvHBTBqkzFrJ633Ge/nwnaY8t\n9paCBvr1P9bz+CfbOZJTfZCZ9vZqbp29xm8hOGc1y030e3gRP3n1WwDWHTgR0jo5Ty7aSa+HPqOw\npAyDJzXlNuSxxQyfVfOF133PYDwlqyeqqEqqq+wC9+9y/YHQqraC+bv1N7MtIzcsbQpVWblh77Ha\nz84+mlvIvze6r9FQlzLi2tidmUd+UWnNOzYgDe4R0KNdxUDnxH7+A4/TRqb63Z95hXsG7d9uSGP6\n6G7061j7nH1NsvOL/e7XVAI/+YUVfj3avMKq/4iLS8u9FzjJzC2ktKycsU8v46lF/oEyI8e/Quau\nf7gHdK999VteXuZen+ZkFevheC6luHBz5Rm+wfgGd4P/h83MLWTb4Ypg5bmm7tUvf8Mry36ocf19\nz7pA6/afYI+V3vJkZXJOl3Asv5jUGQuDptcyck4z48NNnPvQp+w6mgdUpL8ael5CVl4R863AF6pI\nr+z9jZVSDNW1r37Lb+asp6i0jL8t30O3Bz4JGoDzi0q56MkvQ145NpAxhkufXR72s63a0uAeYa/e\nMIQpPhcSmTokxe/x1tbSBwNSWvLApD5Euyq+socDlk6oq6mvflOr/UvKjN+pePekeOZ8V3W53+in\nlvK/S3Yx7C9LuPf9jew5VsBLS/0XFMut5gDhsfNIHpl5heQWljDmqaWs2XecQydPs2qve0LYtsO5\nHMkp5E/zt/Lut/uqfJ3MvIq2B+b5xz3zFZMCDl6+Lnl6GR+srXog1tMb/Nnrq7zLQ2TkFFa6ZOO/\nggzmTntrNf+0auK/P5rP/I2HWf59lt/r1iQ7v8ibOqtOcak1kG7dv+2dNdw9Z31Izz1bfBJkuY7q\nHLDKfItLy/mHddYR7Gxww4GTHDx+mme/qNv6S0XW31RdDw7hoqWQZwFPB+i56wbSt4O7Zx7tclBc\nWk7HVv5LJET7lCNOG9mV/p1acq2VOqitnu3i2ZWZz7H82v+HvuaVivdcvP2o98pTVXnGyulX1TvM\nyqs6p+5x53vriI9x8da0oezLPsX98zb7Ld/w4bp0PvQJmmN6tWPu6oPcdUkPv5U2PeMMUBHcs/OL\nWLHrGHlWT66qmcMHjp/i9/9vI4M6t6Rls2iSEtyVTOsOnODql4MfJPdnn+Kiv/pfwWv2t/spKC7j\n8av6E+NyD8wf8rnAS/MYJ9PeqljTxxg4XVxGQXEpb6zcy8jubTldUsb4gOosz0S3YaltyMg9zbu3\nXEBq2zgOHj/Fy8t288iV/Yl2OfzGHaBi3KS4rJznF3/PnqwCHpzch2RrjGjHkVwmPr+CBb8ZRf9O\nLf2eG+pwsed3lJQQw+oHLw3xWe7P/dBHW7j3snPp5PP/wbOy66ebM1iwOYNeyQlM6NeeXu0Tqn29\notJyPNm4YGsglVjFAMFKf0MReP0HcE/469iqWdAijIaiwT1Cvpkx1vtHkNo2DoC28TGICPuemIwx\nhrJygyvgDyzG+uP43Xj3pKlu1nMDxbgc3h5EVR7+UT9+8cYq7/3+nVqw5ZB//vT/bkzj9neqXrL4\nTMsvKvUG3l2Z+dXu+7v/t5Hv9h5n86Ecvvo++AXZ73xvHQvvvoh7/rneewYA1Djb99Jnl+NyCLv/\nMgmgxrLKYEssf7A2nfJyw7PXDQLc5bKeg8vXu/xTDuXGcNXLX7PjiDtd84qVqtr3xOSg7/edtbzF\nmKeXse+JyTzx6Q4Wbs5ge0Ye7/9yhPdvz3hr8d3/XvCXijGBo7mFzP3lCABvrvrLHZmVg7uVdzpV\nXFppfMnXz/7vP0BoB3JffWZ+BkBZeTnP/3Swd7snuN/xnjuFt5AM5q4+yNczxrL8+yyO5hZybVrn\nSq9XXFqOw/rAwaqFPAd83+B+oqCYVs2jqlzP6Y2Ve/lgbTrdk+L474n+y5iUlJUz9pmvGNe7HW/c\nXPtqubrStEyEdGzVzJt7v3tsD966eSgX9axYV15EKgV2gFlXD2DqkBSmX+xeEsFzdamlvx/D5f3b\nM6xrGz68Y0TQ9/zjFX3p06EiZ39OYnO/x390njs9NOSc1t5tLaq4qEkkhXqw+c4K1lUFdoDsgmL+\n+tkOdgccKHwH7KoaGCstN0x56WtW7cn2lpjW1rz1h7y3Xc6KwPH6yr1++5UbvIHdVyjX4M3MLSQx\n3p3e23DwJFe/8rW3577h4EnGPbMs6HwEz0zhbYdzybAGq/db4yd7jxWwwjoAlRvD0h2Z9J25iGGP\nL+br3ceCDnj6trW6qqEth3KCDvQ6HMIWn+WzX/hyN5vT/avIPGnLG9/8jvs+2BT09/P05ztxWkH6\ndJBetifge86Sdx3NY/CjXzDkscVc/5r7APXd3uPc+vZqPt7g/v4eXbCN7Rm5LNiU4Xc9B6hI0ywJ\nWB68oZ3/hhr5AAARwklEQVR9/3ObIJfTUWklyqp0atWMp68d6Lctyumga9s4XvnFEO+2YL32otIy\n5tx+AXuOFdCnfQuaRTu5+cJU3v5mH4M6t/KeMp6bHM+B46fIyiuiZfOoSq/jq218TLVlimebC7q2\n8euhA/zLJ8B6/Mnngiy+6/MH2njwJNdZ/+HrKnXGQr57YJzfXINAgQHDI/d0Cav2ZhPjcvqlpHxd\n9vxyvzTTlkO5fqmDH7IK6NiycoluQVEpWw7lcMX/Viwx8eG6dG4d1ZVJL6zwbtuekctea/A4M6+I\nn7/uPhv84S+TMMaw7sBJfvI3/9Rhjwc/5c9T+nHjiNRK7+t5v8CzEqeIX1sA/r3JP82XGLA8d/cH\nPuG2UV2585Ie3m3z1h2it5W6eXTBNp67bhALNmVw9fmd6NCymXcCXpR1sPWcIR4vKObbPdkA3s+z\nZEemt1PkURDQGahuVnlD0uBuU06HUFZumHF5b1JaN+PX/1jPBV0TadU8mvO7VPwH+NOV/bh1VFfa\nxEWz1aoSGdylNV9sc/cyWsRG0a9jC359SQ/v6a/HWzcPZeb82q8pD3BdWmfmrqlYUOvq8zsxb13l\nIBtuf7l6AOOe+arG/UIZ4A2neesPkVdYWuvfw7hnv6r2oADBxw++P+p/phIs91xQVMam9MrzKyb/\n7wq/+09+FnzgsfsDn1Tbrpkfb2V832Q6tGzGkZxCVuzK8kujfH80j8t86tmDHYQ/23LE735ckDWc\nXl+5t9KZkGdi2boDJ7n4qWUAfL7tKIM7t+Ltb/YB7k5XSVk5dwb83QeeVQQeeH0PnGmPLaZLm4px\ngmGPL+ataUPp19E/tdUQNLjb1Ed3jmR3Vh5XDXZX31zev0OVNd2d27jTM8O6tuHL311M17ZxPGnV\ndLscwsK7L/Lb/4FJvZk+2r2CZtxnof8JiVTkeGddPYDR5yZx1z/WIQLP/mQQvxzdnRveWEWmlZON\ndjooDvNMxKrGKCLN0/NNaVX5GgPVqSmwVyWwuimwmgfcg6snTlV+/XBWQI6Y9SXP/mQgD/5rC6dL\nyvyqsC4LmKgU7ADkqYDxiHY5/CbkVSVYbf7GgyfZ6FOiuutoHuf96fNK+10VMHBeEDA47ZvGO5Zf\n5Hdmm5lXxMvLfuCln51fYxvrS3PuNjUgpaU3sEP1k3V8dUuKR0QqBpOCPO32iyqWQH7xZ+dzrU/5\n5hs3pfHU1PMqPwk4t10CI7olcuuorjgc4q0xv9xaZKxX+wTmTB/u3f8PE93r6fuOE3hq2utKRLhv\nQi+GnNOaqn4lL1zvHrQL9XdWH1MGdSQxLto7AJrSunkNz6ifx37cP+h230lpvrafgQlKH2047O39\nPv158MB8eQgL0YE7uAeumlpXG9NzqkyH+Qo8M6ppddaFmzL4ckf11WXhoMFdBfXOLcO4c0x3kuIr\nFi37+K6RzLp6gF/FQI928TzlMwYwvFsiU4ek8NFdI5n/65FcfG7FIPHDV/ZlzvTh/NGamFWxsFbF\n6/kGb09PzTcf7Blv6Nuhhbds1FM5BO6c6/Y/Twz6mZ6xnnvXJT348I4L2TOrcqVJ5zbNuLx/e26/\nqCtf/NfooK9TnR8P6ljzTpa4aCf/89PB9Gqf4B2ATGldued++0Vda90OgDSfgXGPmiqoPK4f1gWA\nBZtqV0teF/tCmG3qe4CvTiTq9APPMNJP1Lxkte9EuYZSY3AXkTdFJFNEgiZXxe0FEdktIptEpOHP\nN1SD65mcwB8m9vYL5AM7t/L+p69KsygnIsKgzq04L6UVs28ZxpUD3QFvRLfq1+WBiuAe43IwwZq9\nO+Ny94JtOx6dyKgebenYMpb7JvRicJdWQMWKmwDL7hvjXT7Y1x1junNNwASxQA6Bf905kiingwcn\n9/VbMjmYu8f2qLRt6pDKpXdV8WQZmvnUPncKEtw9g46xUf7/XR+c1Kfa128R4lmO74xpjx+d1yGk\n5wbyvdZBlzahnYUcDGFRNN+DfnWptW9+yPbe3v34mV02+ryUlozsUfPfOBC0RDPcQum5vw0E7wq5\nXQ70tH6mA6/Uv1mqsXIESWU8d90gtv15QqUaYU8p5vk+Pcwop4OZV/Tl378ZRde2cex7YjI9kxMY\n0T2R2CgnzaKdfHP/OC7p3Y621lmFbxCpqs46sPbYY/0fx/PjQR2Zfcsw9sya7H1ND09Vxfu/rFxe\nmpbaptK2YP+5F987mqW/H1Npu2cROk8J5IBOLf0m6bSNj+He8eeS0roZd4/twZNT/aukPOWNHtcP\n60KCT+lqlLPyd3H9sM5cERC4p/uk2cCdDhvRPZHR5yYxfXQ3XvWpwvJY9NvR3stQejz64/5sePgy\nBlh18AvuHlXpecEE5vAfnNSH20ZVnK08NLkPPx3WmXFWRVngOMwL1w+udIBKad0saClxjKvhkhUf\n/OrCoKWVgRbfe7F3clhDqnE0zBizXERSq9llCvCOcS808R8RaSUiHYwxDX8+p84aE/olV7n6pNMh\nQYPueSmtWPr7MaQG1NvfMiq0NMRdl/SgT4cWjOlVkfoJlicPFuQ8WsdF+02MCfTxr0dSWmaCVmH4\nHghioxw8/mN3yurpawfy2vIf+P5oPgkxLnq0S/CurwPu9YJG9WzrTcE8NLkvrZtH88iUfn4B6Z1b\nhtHXWkvo3svcgfTuOeu9jycGHIhaxLoY3yfZWzsfbFnm5tEunr52oF+6JTmgDPKOi7sjIrxzyzAA\nlu2sXJ/dq30CvdoncMV5HXhy0U7W7jvBDcPPAWDO9OGcPFVMfDUTmoZ3a0O/ji15I6CKBdwHvY0+\nK4zeOqorIsLvJ/RiyY7MShOPLuyeyKV92tF3ZkXJam4V6xDtfOxyDp08TV5hCROf96/6eWhyH44X\nFDOuTzLXvOI/aHrnmO68vmIvxWXl/PfE3gzv1obScuM3Ozza5eDwyYoB4bRzWiPivqLbCp9Jac2D\nnFk2hHBUy3QCfC8SmW5t0+DehLz88yEhreEeqGs9qleiXQ7vFZ8u6tnW7z/Qyz8/n51H8pg2MjXo\n2USoYlxOPHE9cNZv2wR3z3nqkBS/uQdTh6Qwvm8yAx/53Lt2S8dWsVzUsy13j+vJ0IAef+c2zXni\nmopB6G5JcezJKgh6UHrkyn48PH8rV5/fqVJN96DOrRjXJxkR4cN16XSwgvajU/rxx48r6vZjo5y8\ne+sw7zIM7RL8DxKBZ1ie5RGCOScxrlLlR3yMi/ggB8M+HVqwPSOXS/sk8/pN7usN/9f4c/3mEVzW\nN5n+nVr6DeR62uN5Td+DVlUzdK+/oHL6MM4Kqu6zo4ozpN+NP5dnvvieKwd1pF1C8B71uD7tOJJb\nyLx1h0hKiGFwl9bsDDKpbMqgjt7rHn9gXcjnpaW7/f42z9QSBGe0FFJEpuNO3dClS/W5W9W4OB2C\n03Hm1s0I9ObNQ/0WAZs0oAOTBtQtb1yVF64fzC/fXcvz1w1if/YpkuJj+Pb+sSTGxVTa1xOYPb1z\nl9PBu7deENL7RDncvfdgpX83XZjKTRemAhUzSJNbxPDv34zyBqZOrdz/JiXEsOPRicS4HH7BHeCi\nnkmkJjZnX/Ypb57/qsGd/FJkHuEoGtr3xGTvhKgLfa6JEB/jYuqQFE6XlDG8WyJXD+4EBC+3jPMG\n9+o7ETseneidXXr3uJ7e6pl/3TXSb78BnVqy+VAOvx7bg1tGdQ16dtYrOYGdR/Po1jbeO9vVM64Q\nOAYC8IeJvZk2sqvfwnN3XNydUT3aMuWlr6t8XkMIR3A/BPiODqRY2yoxxrwGvAaQlpYW2fVCla1E\nOR11XugpVBP6tWfbnyf4pZg6tAxel9482sWrvzg/aLCsyWX9ktl5NI82AT3zQEnxMUQ7HfxhQm+/\nHueFPdrywpe7Gd4t0dtLXPnfl1TKB8+ZPpyNB0/SIjaKvbPca+QEWzvFc5C5sHui34BlqDxnEP07\nteSr+8ZUGmgNnHENUGZF97E+M7fjYtyfZUK/9kFX5mzdPIoTp0r8esb3jj+XhBgXAzu34txk/wXF\n/n7rBRw8cQoRqRTY1z50KbO/3c+dY7p7X88zc9WT+mvvk866oGsb72PtA9JcDocwsHMrLuubzOfb\njhJbzZlQOEkoazJbOfcFxphKRbIiMhn4NTAJuAB4wRgzrKbXTEtLM2vWnD0LUil1tvBceaouV+3y\nKCwpC9vp/6b0k1z54tfepSqg6nRIoNzCElxVjLlUZ9WebK577T88cfUAfupToZWZV0jr5tGs2XeC\nTekn+eXF3b2PnSoupazckBBbv7kQVVm2M5Ob31rN1zPGege+Bzy8iLyiUr57cFyVKR2PsnLDyVPF\nlcZKaktE1hpj0mrcr6bgLiJzgDFAW+Ao8DAQBWCMeVXch/oXcVfUnAKmGWNqjNoa3JVqPJbtzOTC\n7m05dPI0RaVl9G4f/ovGBPohK59ubeOqXInxbDDyiS85dPI0G2aOp1Xz6s+0wiVswb2haHBXSjV2\ne48V8MnmDO4c0/2MHYRCDe66toxSStVR17Zx3HVJ5clsZwNdfkAppWxIg7tSStmQBnellLIhDe5K\nKWVDGtyVUsqGNLgrpZQNaXBXSikb0uCulFI2FLEZqiKSBeyv49PbAsdq3Mte9DM3DfqZm4b6fOZz\njDFJNe0UseBeHyKyJpTpt3ain7lp0M/cNJyJz6xpGaWUsiEN7kopZUONNbi/FukGRIB+5qZBP3PT\n0OCfuVHm3JVSSlWvsfbclVJKVaPRBXcRmSgiO0Vkt4jMiHR7wkVEOovIUhHZJiJbReQea3sbEflC\nRHZZ/7a2touIvGD9HjaJyPnVv8PZSUScIrJeRBZY97uKyCrrc80VkWhre4x1f7f1eGok210fItJK\nRD4QkR0isl1ERtj5exaR/7L+preIyBwRibXj9ywib4pIpohs8dlW6+9VRG6y9t8lIjfVtT2NKriL\niBN4Cbgc6AtcLyJ9I9uqsCkFfmeM6QsMB+6yPtsMYIkxpiewxLoP7t9BT+tnOvDKmW9yWNwDbPe5\n/1fgOWNMD+AEcKu1/VbghLX9OWu/xup/gM+MMb2Bgbg/vy2/ZxHpBNwNpFnXYHYCP8We3/PbuC83\n6qtW36uItMF9KdMLgGHAw54DQq0ZYxrNDzACWORz/37g/ki3q4E+68fAeGAn0MHa1gHYad3+G3C9\nz/7e/RrLD5Bi/cGPBRYAgntihyvw+wYWASOs2y5rP4n0Z6jDZ24J7A1su12/Z6ATcBBoY31vC4AJ\ndv2egVRgS12/V+B64G8+2/32q81Po+q5U/GH4pFubbMV61R0MLAKSDbGZFgPHQGSrdt2+F08D/wB\nKLfuJwInjTGl1n3fz+T9vNbjOdb+jU1XIAt4y0pHvS4icdj0ezbGHAKeBg4AGbi/t7XY/3v2qO33\nGrbvu7EFd9sTkXjgQ+C3xphc38eM+1Bui/ImEbkCyDTGrI10W84wF3A+8IoxZjBQQMWpOmC777k1\nMAX3Qa0jEEfl1EWTcKa/18YW3A8BnX3up1jbbEFEonAH9veMMfOszUdFpIP1eAcg09re2H8XI4Er\nRWQf8E/cqZn/AVqJiOfC7b6fyft5rcdbAtlnssFhkg6kG2NWWfc/wB3s7fo9XwrsNcZkGWNKgHm4\nv3u7f88etf1ew/Z9N7bgvhroaY20R+MemJkf4TaFhYgI8Aaw3RjzrM9D8wHPiPlNuHPxnu03WqPu\nw4Ecn9O/s54x5n5jTIoxJhX39/ilMebnwFJgqrVb4Of1/B6mWvs3ut6tMeYIcFBEelmbxgHbsOn3\njDsdM1xEmlt/457Pa+vv2Udtv9dFwGUi0to667nM2lZ7kR6AqMOAxSTge+AH4MFItyeMn2sU7lO2\nTcAG62cS7nzjEmAXsBhoY+0vuCuHfgA2465GiPjnqONnHwMssG53A74DdgP/D4ixtsda93dbj3eL\ndLvr8XkHAWus7/ojoLWdv2fgEWAHsAV4F4ix4/cMzME9rlCC+wzt1rp8r8At1uffDUyra3t0hqpS\nStlQY0vLKKWUCoEGd6WUsiEN7kopZUMa3JVSyoY0uCullA1pcFdKKRvS4K6UUjakwV0ppWzo/wMA\nR+tTua9IxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f21587a7940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Jaonsianeeeeeee\n",
      " Naltiaeneeeeeee\n",
      " Ehteteeeeeeeeee\n",
      " Wisldaeeeeeeeee\n",
      " Meroeeeeeeeeeee\n",
      " Oltkseeeeeeeeee\n",
      " FurQsieeeeeeeee\n",
      " Kricaaeeeeeeeee\n",
      " Bergeeneeeeeeee\n",
      " Rhareeeeeeeeeee\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumponeeeeeeee\n",
      " Trumpeeeyeeeeee\n",
      " Trumpaewaeeeeee\n",
      " Trumpapeeeeeeee\n",
      " Trumpastteeeeee\n",
      " Trumpeleeeeeeee\n",
      " Trumpayeeeeeeee\n",
      " Trumpardaeeeeee\n",
      " Trumpineeeeeeee\n",
      " Trumpeeaeeeeeee\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"RANzkX9GzA76jYTP\"\n",
    "COURSERA_EMAIL = \"sksr140@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59669b992f6a4493ba43afb992ffe723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 55)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
